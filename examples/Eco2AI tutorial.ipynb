{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wellcome to **eco2ai** tutorial\n",
    "\n",
    "Install the following libraries into your python environment, if they are not already installed:\n",
    "\n",
    "***pip install numpy***\n",
    "***pip install pandas***\n",
    "***pip install matplotlib***\n",
    "***pip install pillow***\n",
    "***pip install tensorflow***\n",
    "\n",
    "Install the eco2ai library in your python environment:\n",
    "\n",
    "***pip install eco2ai***\n",
    "\n",
    "and run this jupyter notebook as a usage example!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eco2ai\n",
    "from eco2ai import track\n",
    "\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras import utils\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import random\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepearing Mnist Dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "fig, axs = plt.subplots(1, 10, figsize=(25, 3)) \n",
    "for i in range(10): \n",
    "    label_indexes = np.where(y_train==i)[0] \n",
    "    index = random.choice(label_indexes) \n",
    "    img = x_train[index] \n",
    "    axs[i].imshow(Image.fromarray(img), cmap='gray') \n",
    "\n",
    "plt.show() \n",
    "\n",
    "y_train = utils.to_categorical(y_train, 10)\n",
    "y_test = utils.to_categorical(y_test, 10)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Creating tracker object\n",
    "tracker = eco2ai.Tracker(project_name=\"mnist\", experiment_description=\"Convolutional model\")\n",
    "#start command\n",
    "tracker.start()\n",
    "\n",
    "batch_size = 256 \n",
    "\n",
    "model = Sequential()\n",
    "model.add(BatchNormalization(input_shape=(28, 28, 1)))\n",
    "model.add(Conv2D(16, (3, 3), padding='same', activation='relu'))\n",
    "model.add(Conv2D(16, (3, 3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=2, validation_data=(x_test, y_test),verbose=1)\n",
    "\n",
    "plt.plot(history.history['accuracy'], \n",
    "         label='Доля верных ответов на обучающем наборе')\n",
    "plt.plot(history.history['val_accuracy'], \n",
    "         label='Доля верных ответов на проверочном наборе')\n",
    "plt.xlabel('Эпоха обучения')\n",
    "plt.ylabel('Доля верных ответов')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#end command\n",
    "tracker.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking results\n",
    "df = pd.read_csv('emission.csv',sep =',')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Creating tracker object\n",
    "tracker = eco2ai.Tracker(project_name=\"mnist\", experiment_description=\"simple model\")\n",
    "#start command\n",
    "tracker.start()\n",
    "\n",
    "batch_size = 256 \n",
    "\n",
    "model = Sequential()\n",
    "model.add(BatchNormalization(input_shape=(28, 28, 1)))\n",
    "model.add(Conv2D(16, (3, 3), padding='same', activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=2, validation_data=(x_test, y_test),verbose=1)\n",
    "\n",
    "plt.plot(history.history['accuracy'], \n",
    "         label='Доля верных ответов на обучающем наборе')\n",
    "plt.plot(history.history['val_accuracy'], \n",
    "         label='Доля верных ответов на проверочном наборе')\n",
    "plt.xlabel('Эпоха обучения')\n",
    "plt.ylabel('Доля верных ответов')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#end command\n",
    "tracker.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking results\n",
    "df = pd.read_csv('emission.csv',sep =',')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Creating tracker object\n",
    "tracker = eco2ai.Tracker(\n",
    "    project_name=\"Mnist, testing decorators\", \n",
    "    experiment_description=\"simple model\",\n",
    "    file_name=\"emission.csv\"\n",
    "    )\n",
    "\n",
    "#using decorators\n",
    "@track\n",
    "def train_func():\n",
    "    batch_size = 256 \n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(BatchNormalization(input_shape=(28, 28, 1)))\n",
    "    model.add(Conv2D(16, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    history = model.fit(x_train, y_train, batch_size=batch_size, epochs=2, validation_data=(x_test, y_test),verbose=1)\n",
    "\n",
    "    plt.plot(history.history['accuracy'], \n",
    "             label='Доля верных ответов на обучающем наборе')\n",
    "    plt.plot(history.history['val_accuracy'], = 8\n",
    "             label='Доля верных ответов на проверочном наборе')\n",
    "    plt.xlabel('Эпоха обучения')\n",
    "    plt.ylabel('Доля верных ответов')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "train_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking results\n",
    "df = pd.read_csv('emission.csv',sep =',')\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
